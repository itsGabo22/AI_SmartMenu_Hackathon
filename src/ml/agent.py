"""Agente de IA Inteligente para SmartMenu con OpenAI SDK."""
import os
import sys
from typing import Dict, Any, Optional, List
from dotenv import load_dotenv
from src.data.products import get_all_products, search_products

# Cargar .env desde la raÃ­z del proyecto
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
env_path = os.path.join(project_root, '.env')
load_dotenv(env_path)

OPENAI_AVAILABLE = False
openai_client = None

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    print("âš ï¸ OpenAI SDK no estÃ¡ disponible. Instala con: pip install openai")
    pass


class SmartMenuAgent:
    """Agente conversacional inteligente con OpenAI SDK."""
    
    def __init__(self):
        api_key = os.getenv("OPENAI_API_KEY")
        self.use_openai = OPENAI_AVAILABLE and bool(api_key)
        self.user_chat_history: List[Dict[str, str]] = []
        self.restaurant_chat_history: List[Dict[str, str]] = []
        self.client = None
        self.all_products = get_all_products()
        
        print(f"ğŸ”§ Cargando agente...")
        print(f"   Ruta .env: {env_path}")
        print(f"   .env existe: {os.path.exists(env_path)}")
        print(f"   API Key presente: {bool(api_key)}")
        print(f"   OpenAI disponible: {OPENAI_AVAILABLE}")
        
        if self.use_openai:
            try:
                from openai import OpenAI
                self.client = OpenAI(api_key=api_key)
                print("âœ… Agente iniciado con OpenAI GPT-3.5-turbo")
            except Exception as e:
                print(f"âŒ Error inicializando OpenAI: {e}")
                print(f"   Verifica que OPENAI_API_KEY estÃ© configurado correctamente en .env")
                self.use_openai = False
        else:
            if not api_key:
                print("âš ï¸ OPENAI_API_KEY no encontrado en .env")
            if not OPENAI_AVAILABLE:
                print("âš ï¸ OpenAI SDK no estÃ¡ disponible")
            print("âœ… Agente iniciado en modo local inteligente")

    def _get_context_for_user(self) -> str:
        """Crea un contexto con informaciÃ³n del menÃº para el agente."""
        products_info = ""
        for product in self.all_products[:10]:  # Primeros 10 productos
            products_info += f"- {product['name']}: ${product['price']} ({product['prep_time']}min, {product['calories']}kcal)\n"
        
        return f"""Eres un asistente amigable de restaurante experto en recomendar platos.
Tienes acceso a este menÃº:

{products_info}

Cuando el cliente pregunte:
- SÃ© amigable, entusiasta y personalizado
- Recomienda basÃ¡ndote en sus preferencias explÃ­citas
- Incluye precios, tiempo de preparaciÃ³n y calorÃ­as
- Sugiere combinaciones complementarias
- Si piden algo especÃ­fico, busca opciones similares

Responde siempre en espaÃ±ol, de forma conversacional y natural."""

    def _get_context_for_restaurant(self) -> str:
        """Crea un contexto para el asesor del restaurante."""
        return """Eres un asesor experto en operaciones de restaurantes.
Tu tono es profesional, directo y basado en datos.
Cuando el gerente pregunte:
- Proporciona recomendaciones operativas prÃ¡cticas
- Analiza datos de demanda y predicciones
- Sugiere acciones concretas para mejorar eficiencia
- Considera costo-beneficio
- Proporciona insights sobre gestiÃ³n del personal y stock

Responde siempre en espaÃ±ol, de forma clara y accionable."""

    def chat_user(self, user_message: str, menu_context: Optional[Dict] = None) -> str:
        """Chat para clientes con OpenAI."""
        print(f"\nğŸ“ chat_user llamado")
        print(f"   use_openai: {self.use_openai}")
        print(f"   client exists: {self.client is not None}")
        
        if self.use_openai and self.client is not None:
            try:
                print(f"   âœ Usando OpenAI (gpt-3.5-turbo)")
                # Construir historial de mensajes
                messages: List[Dict[str, str]] = [
                    {
                        "role": "system",
                        "content": self._get_context_for_user()
                    }
                ]
                
                # AÃ±adir historial reciente
                for msg in self.user_chat_history[-6:]:
                    messages.append({
                        "role": msg["role"],
                        "content": msg["content"]
                    })
                
                # AÃ±adir mensaje actual
                messages.append({
                    "role": "user",
                    "content": user_message
                })
                
                print(f"   ğŸ“¤ Enviando a OpenAI con {len(messages)} mensajes")
                # Invocar OpenAI
                response = self.client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=messages,  # type: ignore
                    temperature=0.7,
                    max_tokens=500
                )
                result = (response.choices[0].message.content or "").strip()
                print(f"   âœ… Respuesta de OpenAI recibida ({len(result)} chars)")
                
                # Guardar en historial
                self.user_chat_history.append({"role": "user", "content": user_message})
                self.user_chat_history.append({"role": "assistant", "content": result})
                
                return result
            except Exception as e:
                error_msg = str(e)
                print(f"   âŒ Error con OpenAI: {error_msg}")
                if "insufficient_quota" in error_msg or "429" in error_msg:
                    print(f"   âš ï¸  Tu cuenta OpenAI ha agotado la cuota.")
                    print(f"   ğŸ“‹ Visita: https://platform.openai.com/account/billing/overview")
                # Fallback a modo local
                print(f"   âœ Fallback a modo local")
                return self._chat_local_user(user_message)
        else:
            # Modo local si no hay OpenAI
            print(f"   âœ Usando modo local (use_openai={self.use_openai}, client={self.client})")
            return self._chat_local_user(user_message)

    def _chat_local_user(self, user_message: str) -> str:
        """Chat local inteligente para clientes."""
        msg_lower = user_message.lower()
        
        # Saludos
        if any(word in msg_lower for word in ["hola", "buenos", "buenas", "hi", "hey"]):
            response = "Â¡Hola! ğŸ‘‹ Bienvenido a nuestro restaurante. Â¿QuÃ© tipo de comida te apetece hoy? Tenemos opciones deliciosas para todos los gustos. ğŸ˜Š"
        
        # BÃºsqueda especÃ­fica de productos
        elif "quÃ©" in msg_lower or "recomienda" in msg_lower or "sugiere" in msg_lower:
            products = self._find_relevant_products(user_message)
            response = self._generate_smart_recommendation(products, user_message)
        
        # BÃºsqueda por precio
        elif "precio" in msg_lower or "barato" in msg_lower or "caro" in msg_lower:
            products = self._find_relevant_products(user_message)
            response = self._recommend_by_price(products, msg_lower)
        
        # BÃºsqueda por salud
        elif "saludable" in msg_lower or "sano" in msg_lower or "ligero" in msg_lower:
            products = self._find_relevant_products(user_message)
            response = self._recommend_healthiest(products)
        
        # BÃºsqueda por velocidad
        elif "rÃ¡pido" in msg_lower or "rÃ¡pida" in msg_lower or "prisa" in msg_lower:
            products = self._find_relevant_products(user_message)
            response = self._recommend_fastest(products)
        
        else:
            # Buscar y describir
            products = search_products(user_message)
            if products:
                response = self._describe_product_detailed(products[0])
            else:
                response = f"Estoy buscando opciones para '{user_message}'... ğŸ”\n\nNuestros platos mÃ¡s populares son: Hamburguesa ClÃ¡sica, Ensalada CÃ©sar, SalmÃ³n a la Parrilla.\n\nÂ¿Alguno de estos te llama la atenciÃ³n?"
        
        self.user_chat_history.append({"role": "user", "content": user_message})
        self.user_chat_history.append({"role": "assistant", "content": response})
        
        return response

    def _find_relevant_products(self, query: str, limit: int = 5) -> List[Dict]:
        """Busca productos relevantes."""
        query_lower = query.lower()
        
        # BÃºsqueda directa
        direct = search_products(query)
        if direct:
            return direct[:limit]
        
        # BÃºsqueda por palabra clave
        keywords = {
            "desayuno": ["cafÃ©", "huevos", "pancakes"],
            "almuerzo": ["hamburguesa", "ensalada", "pizza", "sÃ¡ndwich"],
            "merienda": ["torta", "frappuccino", "brownie"],
            "cena": ["salmÃ³n", "carne", "pasta"],
            "saludable": ["ensalada", "salmÃ³n"],
            "rÃ¡pido": ["hamburguesa", "sÃ¡ndwich"],
        }
        
        for keyword, products_ids in keywords.items():
            if keyword in query_lower:
                relevant = [p for p in self.all_products 
                           if any(pid in p.get("name", "").lower() for pid in products_ids)]
                if relevant:
                    return relevant[:limit]
        
        return self.all_products[:limit]

    def _generate_smart_recommendation(self, products: List[Dict], user_msg: str) -> str:
        """Genera recomendaciÃ³n inteligente."""
        if not products:
            return "Disculpa, no encuentro ese producto. Â¿QuÃ© tipo de comida prefieres?"
        
        best = products[0]
        response = f"ğŸŒŸ **Mi recomendaciÃ³n: {best['name']}**\n\n"
        response += f"{best['description']}\n\n"
        response += f"ğŸ’° ${best['price']:.2f} | â±ï¸ {best['prep_time']} min | ğŸ”¥ {best['calories']} kcal\n"
        response += f"ğŸ¥˜ Con: {', '.join(best['ingredients'][:3])}\n"
        
        if len(products) > 1:
            response += f"\nğŸ“Œ TambiÃ©n te recomendarÃ­a: **{products[1]['name']}** (${products[1]['price']:.2f})"
        
        response += "\n\nÂ¿Quieres algo mÃ¡s?"
        return response

    def _recommend_by_price(self, products: List[Dict], msg: str) -> str:
        """Recomienda por precio."""
        sorted_products = sorted(products, key=lambda x: x.get("price", 999))
        best = sorted_products[0]
        
        response = f"ğŸ’° **OpciÃ³n econÃ³mica: {best['name']}**\n"
        response += f"Precio: ${best['price']:.2f}\n"
        response += f"{best['description']}\n"
        response += f"â±ï¸ {best['prep_time']} min | ğŸ”¥ {best['calories']} kcal"
        
        return response

    def _recommend_healthiest(self, products: List[Dict]) -> str:
        """Recomienda lo mÃ¡s saludable."""
        sorted_products = sorted(products, key=lambda x: x.get("calories", 999))
        best = sorted_products[0]
        
        response = f"ğŸ¥— **OpciÃ³n mÃ¡s saludable: {best['name']}**\n\n"
        response += f"{best['description']}\n"
        response += f"ğŸ”¥ {best['calories']} kcal | ğŸ’° ${best['price']:.2f} | â±ï¸ {best['prep_time']} min"
        
        return response

    def _recommend_fastest(self, products: List[Dict]) -> str:
        """Recomienda lo mÃ¡s rÃ¡pido."""
        sorted_products = sorted(products, key=lambda x: x.get("prep_time", 999))
        best = sorted_products[0]
        
        response = f"âš¡ **La mÃ¡s rÃ¡pida: {best['name']}**\n"
        response += f"Tiempo: {best['prep_time']} minutos\n"
        response += f"{best['description']}\n"
        response += f"ğŸ’° ${best['price']:.2f}"
        
        return response

    def _describe_product_detailed(self, product: Dict) -> str:
        """Describe un producto en detalle."""
        response = f"**{product['name']}** âœ¨\n\n"
        response += f"ğŸ“ {product['description']}\n\n"
        response += f"ğŸ’° Precio: ${product['price']:.2f}\n"
        response += f"â±ï¸ Tiempo de preparaciÃ³n: {product['prep_time']} minutos\n"
        response += f"ğŸ”¥ CalorÃ­as: {product['calories']} kcal\n"
        response += f"ğŸ¥˜ Ingredientes: {', '.join(product['ingredients'])}\n"
        
        return response

    def chat_restaurant(self, user_message: str, prediction_data: Optional[Dict] = None) -> Dict[str, Any]:
        """Chat para gerentes con OpenAI."""
        print(f"\nğŸ“ chat_restaurant llamado")
        print(f"   use_openai: {self.use_openai}")
        print(f"   client exists: {self.client is not None}")
        
        if self.use_openai and self.client is not None:
            try:
                print(f"   âœ Usando OpenAI (gpt-3.5-turbo)")
                # Incluir datos de predicciÃ³n en el contexto
                context = self._get_context_for_restaurant()
                if prediction_data:
                    context += f"\n\nDatos actuales de predicciÃ³n:\n"
                    context += f"- Producto estrella: {prediction_data.get('producto_estrella', 'N/A')}\n"
                    context += f"- Demanda: {prediction_data.get('demanda', 'N/A')}\n"
                    context += f"- Cantidad estimada: {prediction_data.get('cantidad_estimada', 'N/A')}\n"
                
                messages: List[Dict[str, str]] = [
                    {
                        "role": "system",
                        "content": context
                    }
                ]
                
                # Historial
                for msg in self.restaurant_chat_history[-6:]:
                    messages.append({
                        "role": msg["role"],
                        "content": msg["content"]
                    })
                
                messages.append({
                    "role": "user",
                    "content": user_message
                })
                
                print(f"   ğŸ“¤ Enviando a OpenAI con {len(messages)} mensajes")
                # Invocar OpenAI
                response = self.client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=messages,  # type: ignore
                    temperature=0.5,
                    max_tokens=600
                )
                result = (response.choices[0].message.content or "").strip()
                print(f"   âœ… Respuesta de OpenAI recibida ({len(result)} chars)")
                
                # Guardar
                self.restaurant_chat_history.append({"role": "user", "content": user_message})
                self.restaurant_chat_history.append({"role": "assistant", "content": result})
                
                return {"response": result}
            except Exception as e:
                error_msg = str(e)
                print(f"   âŒ Error con OpenAI: {error_msg}")
                if "insufficient_quota" in error_msg or "429" in error_msg:
                    print(f"   âš ï¸  Tu cuenta OpenAI ha agotado la cuota.")
                    print(f"   ğŸ“‹ Visita: https://platform.openai.com/account/billing/overview")
                print(f"   âœ Fallback a modo local")
                return self._chat_local_restaurant(user_message, prediction_data)
        else:
            print(f"   âœ Usando modo local (use_openai={self.use_openai}, client={self.client})")
            return self._chat_local_restaurant(user_message, prediction_data)

    def _chat_local_restaurant(self, user_message: str, prediction_data: Optional[Dict] = None) -> Dict[str, Any]:
        """Chat local para restaurante."""
        msg_lower = user_message.lower()
        pred = prediction_data or {}
        producto = pred.get("producto_estrella", "N/A")
        demanda = pred.get("demanda", "desconocida")
        cantidad = pred.get("cantidad_estimada", 10)
        
        if any(word in msg_lower for word in ["preparar", "stock", "ingredientes", "cocina"]):
            response = (
                f"ğŸ“¦ **Plan de PreparaciÃ³n:**\n\n"
                f"Producto destacado: **{producto}**\n"
                f"Demanda predicha: **{demanda.upper()}**\n"
                f"Unidades proyectadas: **~{int(cantidad * 1.5)}**\n\n"
                f"âœ… Acciones:\n"
                f"1. Pre-calienta la estaciÃ³n\n"
                f"2. Verifica {int(cantidad * 1.5)} porciones\n"
                f"3. Ten 5 extra listas\n"
            )
        else:
            response = (
                f"ğŸ“Š **Estado operativo:**\n\n"
                f"Horario: {pred.get('hora_prediccion', '?')}:00\n"
                f"Producto trending: {producto}\n"
                f"Demanda: {demanda.upper()}\n"
                f"ProyecciÃ³n: {cantidad} unidades\n"
            )
        
        self.restaurant_chat_history.append({"role": "user", "content": user_message})
        self.restaurant_chat_history.append({"role": "assistant", "content": response})
        
        return {"response": response}


def create_agent() -> SmartMenuAgent:
    """Factory para crear una instancia del agente."""
    return SmartMenuAgent()
